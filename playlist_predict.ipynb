{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Setup up imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# load client credentials using .env file\n",
    "# SPOTIPY_CLIENT_ID=YOUR_CLIENT_ID\n",
    "# SPOTIPY_CLIENT_SECRET=YOUR_CLIENT_SECRET\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lets get started by preprocessing our data\n",
    "First we need to load the data from the JSON files given"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing slice: mpd.slice.0-999.json\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'spotify_million_playlist_dataset/data/'\n",
    "\n",
    "playlists = []\n",
    "for file in sorted(os.scandir(DATA_DIR), key=lambda e: e.name):\n",
    "    print(\"processing slice: \" + str(file.name))\n",
    "    data = json.load(open(file.path))\n",
    "    playlists.append(pd.DataFrame(data['playlists']))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's clean up our array of playlists a little bit by combining them into a pandas DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name collaborative  pid  modified_at  num_tracks  num_albums  \\\n",
      "0        Throwbacks         false    0   1493424000          52          47   \n",
      "1  Awesome Playlist         false    1   1506556800          39          23   \n",
      "2           korean          false    2   1505692800          64          51   \n",
      "3               mat         false    3   1501027200         126         107   \n",
      "4               90s         false    4   1401667200          17          16   \n",
      "\n",
      "   num_followers                                             tracks  \\\n",
      "0              1  [{'pos': 0, 'artist_name': 'Missy Elliott', 't...   \n",
      "1              1  [{'pos': 0, 'artist_name': 'Survivor', 'track_...   \n",
      "2              1  [{'pos': 0, 'artist_name': 'Hoody', 'track_uri...   \n",
      "3              1  [{'pos': 0, 'artist_name': 'Camille Saint-SaÃ«n...   \n",
      "4              2  [{'pos': 0, 'artist_name': 'The Smashing Pumpk...   \n",
      "\n",
      "   num_edits  duration_ms  num_artists description  \n",
      "0          6     11532414           37         NaN  \n",
      "1          5     11656470           21         NaN  \n",
      "2         18     14039958           31         NaN  \n",
      "3          4     28926058           86         NaN  \n",
      "4          7      4335282           16         NaN  \n"
     ]
    }
   ],
   "source": [
    "playlists_frame = pd.concat(playlists)\n",
    "print(playlists_frame.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we can begin our analysis (sort of):\n",
    "\n",
    "We'll start by querying the Spotify API with the Spotipy package to get some more details\n",
    "on the songs that are contained within each playlist. Spotify calculates various data for each song\n",
    "such as the time signature, tempo, timbre, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#authorize our API session with credentials stored in the environment variables\n",
    "\n",
    "auth_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spotify provides us with two different types of song data. One is called the [audio features](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/),\n",
    "and the other is the [audio analysis](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis).\n",
    "Essentially, the features are Spotify's interpretation of the audio analysis, it has higher-level attributes\n",
    "like the 'danceability' and 'liveness' of a song. The audio analysis is every single piece of data\n",
    "that Spotify was able to calculate from the songs sound signature.\n",
    "\n",
    "Audio features sounds like it might be a little easier to handle, so we'll define a function to query\n",
    "that data first."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def processSongFeatures(playlist, sp):\n",
    "    songs = playlist['tracks']\n",
    "\n",
    "    # get features for all songs\n",
    "    song_features = []\n",
    "    song_ids = []\n",
    "    for song in songs:\n",
    "        # get song id\n",
    "        song_id = re.sub('spotify:track:', '', song['track_uri'])\n",
    "        song_ids.append(song_id)\n",
    "        print('processing: ' + song['track_name'])\n",
    "        features = sp.audio_features(song_id)[0]\n",
    "        song_features.append(features)\n",
    "\n",
    "    # convert features into dataframe by song id\n",
    "    features_by_id = pd.DataFrame(song_features, index=song_ids)\n",
    "    features_by_id.index.name = 'song_id'\n",
    "    print(features_by_id.head())\n",
    "\n",
    "    # export data\n",
    "    \"\"\"export_dir = playlist['name'] + '-' + playlist['id']\n",
    "    if not os.path.isdir(export_dir):\n",
    "        os.mkdir(export_dir)\n",
    "\n",
    "    features_by_id.to_csv(export_dir + '/features.csv')\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we can work on handling the audio analysis data, this is a little bit more complicated. We'll start\n",
    "by extracting the list of songs in each playlist from our dataframe of playlists. Using Spotify,\n",
    "we query the API for the audio analysis for each song and create a map entry for it so we can associate\n",
    "each song with its analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                                    Throwbacks\n",
      "collaborative                                                false\n",
      "pid                                                              0\n",
      "modified_at                                             1493424000\n",
      "num_tracks                                                      52\n",
      "num_albums                                                      47\n",
      "num_followers                                                    1\n",
      "tracks           [{'pos': 0, 'artist_name': 'Missy Elliott', 't...\n",
      "num_edits                                                        6\n",
      "duration_ms                                               11532414\n",
      "num_artists                                                     37\n",
      "description                                                    NaN\n",
      "Name: 0, dtype: object\n",
      "analyzing: Lose Control (feat. Ciara & Fat Man Scoop)\n",
      "analyzing: Toxic\n",
      "analyzing: Crazy In Love\n",
      "analyzing: Rock Your Body\n",
      "analyzing: It Wasn't Me\n",
      "analyzing: Yeah!\n",
      "analyzing: My Boo\n",
      "analyzing: Buttons\n",
      "analyzing: Say My Name\n",
      "analyzing: Hey Ya! - Radio Mix / Club Mix\n",
      "analyzing: Promiscuous\n",
      "analyzing: Right Where You Want Me - Radio Edit Version\n",
      "analyzing: Beautiful Soul\n",
      "analyzing: Leavin'\n",
      "analyzing: Me & U\n",
      "analyzing: Ice Box\n",
      "analyzing: Sk8er Boi\n",
      "analyzing: Run It!\n",
      "analyzing: Check On It - feat. Bun B and Slim Thug\n",
      "analyzing: Jumpin', Jumpin'\n",
      "analyzing: Soak Up The Sun\n",
      "analyzing: Where Is The Love?\n",
      "analyzing: Stacy's Mom\n",
      "analyzing: Just The Girl\n",
      "analyzing: Yo (Excuse Me Miss)\n",
      "analyzing: Year 3000\n",
      "analyzing: Lip Gloss\n",
      "analyzing: Everytime We Touch - Radio Edit\n",
      "analyzing: Whatcha Say\n",
      "analyzing: Miss Independent\n",
      "analyzing: Party In The U.S.A.\n",
      "analyzing: The Great Escape\n",
      "analyzing: Replay\n",
      "analyzing: Forever\n",
      "analyzing: Your Love Is My Drug\n",
      "analyzing: Closer\n",
      "analyzing: One Less Lonely Girl\n",
      "analyzing: Paper Planes\n",
      "analyzing: Mr. Brightside\n",
      "analyzing: All The Small Things\n",
      "analyzing: Beep\n",
      "analyzing: Somebody To Love\n",
      "analyzing: Dirty Little Secret\n",
      "analyzing: Baby\n",
      "analyzing: A Thousand Miles\n",
      "analyzing: Livin on Sunday\n",
      "analyzing: See You Again\n",
      "analyzing: How Do You Sleep? - Featuring Ludacris\n",
      "analyzing: This Is Me\n",
      "analyzing: My Happy Ending\n",
      "analyzing: Check Yes Juliet\n",
      "analyzing: The Great Escape\n"
     ]
    }
   ],
   "source": [
    "# select just the first playlist (for testing purposes)\n",
    "playlist = playlists_frame.iloc[0]\n",
    "print(playlist)\n",
    "\n",
    "MAX_RETRIES = 5\n",
    "# get the songs from the first playlist\n",
    "songs = playlist['tracks']\n",
    "\n",
    "analyses = {}\n",
    "# collect analyses of songs, dict of (song id : analysis)\n",
    "for i, song in enumerate(songs):\n",
    "    song_id = re.sub('spotify:track:', '', song['track_uri'])\n",
    "    # sometimes the api request times out, we'll skip the song if it exceeds the max retries\n",
    "    for request_attempt in range(MAX_RETRIES):\n",
    "        print('analyzing: ' + song['track_name'])\n",
    "        try:\n",
    "            a = sp.audio_analysis(track_id=song_id)\n",
    "        except requests.exceptions.ReadTimeout as rto:\n",
    "            print('request to Spotify timed out for: ' + song['track_name'])\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    # remove some useless crap\n",
    "    a.pop('meta')\n",
    "    analyses[song_id] = a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before moving on, lets check out what an analysis looks like so we can decide how we want to\n",
    "structure our data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track{'num_samples': 4853940, 'duration': 220.13333, 'sample_md5': '', 'offset_seconds': 0, 'window_secon\n",
      "bars[{'start': 0.25319, 'duration': 1.43706, 'confidence': 0.471}, {'start': 1.69025, 'duration': 1.4400\n",
      "beats[{'start': 0.25319, 'duration': 0.36878, 'confidence': 0.911}, {'start': 0.62197, 'duration': 0.3587\n",
      "sections[{'start': 0.0, 'duration': 6.73147, 'confidence': 1.0, 'loudness': -10.743, 'tempo': 167.388, 'temp\n",
      "segments[{'start': 0.0, 'duration': 0.19773, 'confidence': 0.0, 'loudness_start': -60.0, 'loudness_max_time'\n",
      "tatums[{'start': 0.25319, 'duration': 0.18439, 'confidence': 0.911}, {'start': 0.43758, 'duration': 0.1843\n"
     ]
    }
   ],
   "source": [
    "# remove an (id, analysis) pair from the dictionary\n",
    "analysis_pair = analyses.popitem()\n",
    "\n",
    "# get the JSON response\n",
    "json = analysis_pair[1]\n",
    "# because the analysis is a JSON response (dictionary), we can access it like this\n",
    "[print(str(category) + str(value)[0:100]) for category, value in json.items()]\n",
    "\n",
    "# don't forget to add the pair back\n",
    "analyses[analysis_pair[0]] = analysis_pair[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You know that's kind of messy, here's the [API reference](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis/)\n",
    "for the structure of an audio analysis.\n",
    "\n",
    "TL;DR, the response contains categories like `track` (special one),\n",
    "`bars`, `beats`, etc. `Track` is special because it contains more general data such as the `duration`\n",
    "and `time_signature`, these headers aren't in the other categories. The categories `bars`, `beats`,\n",
    "and `tatums`, are all composed of [time interval objects](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis/#time-interval-object)\n",
    "which are just dictionaries with the start, end and how confident Spotify is that the data is right.\n",
    "\n",
    "This brings us to `sections` and `segments`. `sections` is composed of [section objects](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis/#section-object)\n",
    "which are basically the same as the other categories, just with more dictionary keys-value pairs.\n",
    "`segments` is where it gets more interesting (and where I got stuck). Again, `segments` is composed\n",
    "of another object (aptly named) [segment objects](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis/#section-object).\n",
    "This is another dictionary with a caveat, some of the values are actually arrays, and not just an integer\n",
    "as before. At first, I thought that this nesting would be a problem, but I found that pandas takes care\n",
    "of this on its own, parsing the array as a pandas series.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Moving on...\n",
    "Now we have a dictionary mapping a song to its analysis JSON response. Let's loop through everything\n",
    "and parse it into a pandas Dataframe using a handy function called `json_normalize`. We're also gonna\n",
    "save the song ids for later to make creating our final dataframe a little easier.\n",
    "\n",
    "The catch here is that we're gonna split everything up by each analysis category, and then by song id."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing song: 0UaMYEvWZi0ZqiDOoHU3YI\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 6I9VzXrHxO9rA9A5euc8Ak\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 0WqIKmW4BTrj3eJFmnCKMv\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1AWQoqb9bSvzTjaLralEkT\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1lzr43nnXAijIGYnCT8M8H\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 0XUfyU2QviPAs6bxSpXYG4\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 68vgtRHr7iZHpzGpon6Jlo\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 3BxWKCI06eQ5Od8TY2JBeA\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 7H6ev70Weq6DdpZyyTmUXk\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 2PpruBYCo4H7WOBJ7Q2EwM\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 2gam98EZKrF9XuOkU13ApN\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 4Y45aqo9QMa57rDsAJv40A\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1HwpWwa6bnqqRhK8agG4RS\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 20ORwCJusz4KS2PbTPVNKo\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 7k6IzwMGpxnRghE7YosnXT\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1Bv0Yl01xBDZD4OQP93fyl\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 4omisSlTk6Dsq2iQD7MA07\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 7xYnUQigPoIDAMPVK79NEq\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 6d8A5sAx9TfdeseDvfWNHd\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 4pmc2AxSEq6g7hPVlJCPyP\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 215JYyyUnrJ98NK3KEwu6d\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 0uqPG793dkDDN7sCUJJIVC\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 19Js5ypV6JKn4DMExHQbGc\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1JURww012QnWAw0zZXi6Aa\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 7DFnq8FYhHMCylykf6ZCxA\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1TfAhjzRBWzYZ8IdUV3igl\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1Y4ZdPOOgCUhBcKZOrUFiS\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 6MjljecHzHelUDismyKkba\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 67T6l4q3zVjC5nZZPXByU8\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 34ceTg8ChN5HjrqiIYCn9Q\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 5Q0Nhxo0l2bP3pNjpGJwV1\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 6GIrIt2M39wEGwjCQjGChX\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 4E5P1XyAFtrjpiIxkydly4\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 3H1LCvO3fVsK2HPguhbml0\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 3uoQULcUWfnt6nc6J7Vgai\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 2nbClS09zsIAqNkshg6jnp\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 69ghzc538EQSVon2Gm3wrr\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1kusepF3AacIEtUTYrw4GV\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 7oK9VyNzrYvRFo7nQEYkWN\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 12qZHAeOyTf93YAWvGDTat\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 2jFlMILIQzs7lSFudG9lbo\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 4I2GqMe7L2ccMpUbnDzYLH\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 5lDriBxJd22IhOH9zTcFrV\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 2eJ8ij1T3cNUKiGdcUvKhy\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 5y69gQtK33qxb8a24ACkCy\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1X5WGCrUMuwRFuYU1eAo2I\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 3utIAb67sOu0QHxBE88P1M\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 3jkdQNkDTxxXtjSO4l0o1H\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 5c1sfI6wIQEsSUw0xrkFdl\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 6sqNctd7MlJoKDOxPVCAvU\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "processing song: 1b7vg5T9YKR3NNqXfBYRF7\n",
      "processing category: track\n",
      "processing category: bars\n",
      "processing category: beats\n",
      "processing category: sections\n",
      "processing category: segments\n",
      "processing category: tatums\n",
      "track\n",
      "bars\n",
      "beats\n",
      "sections\n",
      "segments\n",
      "tatums\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "category_frames = {}\n",
    "# iterate through all songs and their analyses\n",
    "for song_id, a in analyses.items():\n",
    "    print('processing song: ' + song_id)\n",
    "    ids.append(song_id)\n",
    "    # collect the analysis data for each category in the songs' analysis\n",
    "    for category, vals in a.items():\n",
    "        print('processing category: ' + category)\n",
    "        norm = pd.json_normalize(vals)\n",
    "        # val_list is a list of dataframes\n",
    "        val_list = category_frames.get(category, [])\n",
    "        # add the new analysis data for the category\n",
    "        val_list.append(norm)\n",
    "        category_frames[category] = val_list\n",
    "\n",
    "[print(name) for name, frame_list in category_frames.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we're getting a little closer to our final, 2 leveled multi-index pandas Dataframe.\n",
    "We're going to use our `ids` array we created earlier to concatenate dataframes by their song ids.\n",
    "This is the second, inner-level multi-index."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "category_tables = {}\n",
    "# concatenate the list of frames in each category to make tables based on song id\n",
    "for cat_name, frame_list in category_frames.items():\n",
    "    category_tables[cat_name] = pd.concat(frame_list, keys=ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can concatenate again based off of the category names to create our outermost multi-index."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# combine the dictionary of categories and their lists of songs\n",
    "category_tables_frame = pd.concat(category_tables.values(), keys=category_tables.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our final pandas dataframe has a structure like this:\n",
    "\n",
    "| level=0   |     level=1           |     start    | ... | timbre            |\n",
    "| :-: | :-: | :-: | :-: | --- |\n",
    "| segments  | 3ELm3eyRhR4tF1ncqzMQEV|   252.15601  | ... | [pandas.Series]   |\n",
    "|    -       |           -            |   258.15601  | ... | [pandas.Series]   |\n",
    "|     -      |           -            |   259.15601  | ... | [pandas.Series]   |\n",
    "|      -     |           -            |   261.15601  | ... | [pandas.Series]   |\n",
    "|        -   | 2pbxqEYiXJTvFsybGGgSAi|   237.02356  | ... | [pandas.Series]   |\n",
    "|       -    |           -            |   248.15601  | ... | [pandas.Series]   |\n",
    "|      -     |           -            |   249.15601  | ... | [pandas.Series]   |\n",
    "|      -     |           -            |   251.15601  | ... | [pandas.Series]   |\n",
    "| tatums  | 3ELm3eyRhR4tF1ncqzMQEV|   252.15601  | ... | NaN   |\n",
    "|    -       |           -            |   258.15601  | ... | NaN   |\n",
    "|     -      |           -            |   259.15601  | ... | NaN   |\n",
    "|      -     |           -            |   261.15601  | ... | NaN   |\n",
    "|        -   | 2pbxqEYiXJTvFsybGGgSAi|   237.02356  | ... | NaN   |\n",
    "|       -    |           -            |   248.15601  | ... | NaN  |\n",
    "|      -     |           -            |   249.15601  | ... | NaN   |\n",
    "|      -     |           -            |   251.15601  | ... | NaN   |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can query the table by using `pandas.groupby()`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}